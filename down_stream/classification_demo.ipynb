{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d4544cce-621b-42c8-8433-84fc0c0b6a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import HTorch\n",
    "import torch\n",
    "import numpy as np\n",
    "import math\n",
    "from data_utils.data_handler import DataHandler\n",
    "from data_utils.relations import Relations\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from ConeModel import *\n",
    "from collections import deque\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b9f473-cd20-4db2-bd71-73bd6a02c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu = torch.device(\"cpu\"); gpu = torch.device(type='cuda', index=0)\n",
    "device = cpu\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13b1eed-0d1c-49a6-b0b6-5d61155c20e4",
   "metadata": {},
   "source": [
    "### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2dd6b0f2-554b-4f22-b5d8-b6eef800ea82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import networkx as nx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e300ce8-8515-4608-8b53-772a620b55f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### load basic edges\n",
    "file_path = '../data_utils/data/maxn/mammal_closure.tsv.train_0percent'\n",
    "df_indexed = pd.read_csv(file_path, delimiter='\\t', encoding='utf-8',header=None)\n",
    "### load vocab\n",
    "filename = '../data_utils/data/maxn/mammal_closure.tsv.vocab'\n",
    "element_index = {}\n",
    "\n",
    "with open(filename, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        index, element = line.strip().split('\\t')\n",
    "        element_index[int(index)] = element"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83c9047d-923e-44be-b250-41325b8c430b",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_load = nx.DiGraph()\n",
    "G_load.add_edges_from(df_indexed.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afed1aa3-08b8-4c75-824a-baef92556fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    " # best radius from validation = raidus from training\n",
    "\n",
    "size = 1179 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "089154fa-f0c8-4640-adbb-c1093cec8886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "### Load model\n",
    "# load_name = '../trained_models/mammal_with_vocab'\n",
    "# hyp_cone = UmbralCone(source = 'infinity', radius = 0.05, size = size, dim = 2, curvature = -1)\n",
    "\n",
    "# load_name = '../trained_models/mammal_with_vocab_epoch_400_model_umbral_90_dim5' \n",
    "# hyp_cone = UmbralCone(source = 'infinity', radius = 0.05, size = size, dim = 5, curvature = -1)\n",
    "\n",
    "load_name = '../trained_models/mammal_with_vocab_epoch_400_model_penumbral_90_dim2_source_origin' \n",
    "hyp_cone = UmbralCone(source = 'origin', radius = 0.1, size = size, dim = 2, curvature = -1)\n",
    "\n",
    "\n",
    "hyp_cone.to(device)\n",
    "hyp_cone.load_state_dict(torch.load(load_name+\".pth\")[\"model_weight\"])\n",
    "vocab = torch.load(load_name+\".pth\")[\"vocab\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ed701c30-7315-4b9e-b317-2fb204685029",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.arange(size)\n",
    "paired = sorted(zip(vocab,inputs))\n",
    "vocab_sorted,inputs_sorted = zip(*paired)\n",
    "new_element_index = dict(zip(inputs_sorted, [element_index[int(word)] for word in vocab_sorted]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d346cd1a-8bee-429a-a20c-3d421132f37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = torch.load(load_name+\".pth\")[\"vocab\"]\n",
    "vocab = [int(i) for i in vocab]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7691a18e-2d24-45ee-acea-eb8d199bcb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### dictionary: from vocab index to embedding index\n",
    "vocab_idx = np.arange(size)\n",
    "emb_idx = [vocab.index(x) for x in vocab_idx]\n",
    "emb_from_vocab = dict(zip(vocab_idx, emb_idx))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b298d14",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cbe5e029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "356\n",
      "696\n",
      "1005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'placental.n.01'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Fina all source nodes\n",
    "def find_source_node(G):\n",
    "    for node in G.nodes():\n",
    "        if G.in_degree(node) == 0:\n",
    "            print(node)\n",
    "\n",
    "find_source_node(G_load)\n",
    "new_element_index[emb_from_vocab[356]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2de35e0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 unguiculata\n",
      "74 ungulata\n",
      "127 bull\n",
      "137 yearling\n",
      "145 livestock\n",
      "198 unguiculate\n",
      "312 hyrax\n",
      "365 tree_shrew\n",
      "389 pachyderm\n",
      "494 carnivore\n",
      "517 plantigrade_mammal\n",
      "530 aquatic_mammal\n",
      "603 rodent\n",
      "634 ungulate\n",
      "664 doe\n",
      "693 pangolin\n",
      "710 aardvark\n",
      "717 primate\n",
      "737 digitigrade_mammal\n",
      "754 bat\n",
      "786 cow\n",
      "809 proboscidean\n",
      "833 lagomorph\n",
      "955 flying_lemur\n",
      "1003 fissipedia\n",
      "1064 buck\n",
      "1105 edentate\n",
      "1106 insectivore\n"
     ]
    }
   ],
   "source": [
    "def find_nodes_n_edges_down(G, source, n):\n",
    "    if n < 0:\n",
    "        return []\n",
    "\n",
    "    visited = set()\n",
    "    queue = deque([(source, 0)])\n",
    "    nodes_at_level_n = []\n",
    "\n",
    "    while queue:\n",
    "        current_node, depth = queue.popleft()\n",
    "\n",
    "        if depth == n:\n",
    "            nodes_at_level_n.append(current_node)\n",
    "            print(current_node, new_element_index[emb_from_vocab[current_node]][:-5])\n",
    "        elif depth < n:\n",
    "            for neighbor in G.successors(current_node):\n",
    "                if neighbor not in visited:\n",
    "                    visited.add(neighbor)\n",
    "                    queue.append((neighbor, depth + 1))\n",
    "                    \n",
    "        \n",
    "    return nodes_at_level_n\n",
    "\n",
    "find_nodes_n_edges_down(G_load, 356, 1);\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "749dbfd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "494 carnivore\n",
      "603 rodent\n",
      "634 ungulate\n",
      "717 primate\n",
      "754 bat\n",
      "809 proboscidean\n",
      "833 lagomorph\n",
      "955 flying_lemur\n",
      "1105 edentate\n",
      "1137 cetacean\n"
     ]
    }
   ],
   "source": [
    "### Find all nodes reprensenting taxonomic orders by hand\n",
    "labels = [494, 603, 634, 717, 754, 809, 833, 955, 1105, 1137]\n",
    "# labels = [494, 603, 634, 717, 754, 809, 955, 1105, 1137]\n",
    "for order in labels:\n",
    "    # print(emb_from_vocab[order])\n",
    "    print(order, new_element_index[emb_from_vocab[order]][:-5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d976cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Find all leaf nodes under each order\n",
    "def find_leaf_nodes_in_orders(G, orders):\n",
    "    leaves_in_orders = {order: [] for order in orders}\n",
    "    \n",
    "    for order in orders:\n",
    "        # Check if the order node is in the graph\n",
    "        if order in G:\n",
    "            # Use BFS to find all leaf nodes under this order\n",
    "            visited = set()\n",
    "            queue = [order]\n",
    "            while queue:\n",
    "                current_node = queue.pop(0)\n",
    "                visited.add(current_node)\n",
    "                children = list(G.successors(current_node))\n",
    "                if not children:  # If no children, it's a leaf node\n",
    "                    if current_node != order:  # Exclude the order node itself\n",
    "                        leaves_in_orders[order].append(current_node)\n",
    "                else:\n",
    "                    # Add children to queue if not visited\n",
    "                    for child in children:\n",
    "                        if child not in visited:\n",
    "                            queue.append(child)\n",
    "\n",
    "    return leaves_in_orders\n",
    "\n",
    "items = find_leaf_nodes_in_orders(G_load, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "60ac688c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leaves under order cetacean:\n",
      "282\n",
      "Leaves under order cetacean:\n",
      "104\n",
      "Leaves under order cetacean:\n",
      "244\n",
      "Leaves under order cetacean:\n",
      "78\n",
      "Leaves under order cetacean:\n",
      "32\n",
      "Leaves under order cetacean:\n",
      "8\n",
      "Leaves under order cetacean:\n",
      "18\n",
      "Leaves under order cetacean:\n",
      "1\n",
      "Leaves under order cetacean:\n",
      "16\n",
      "Leaves under order cetacean:\n",
      "24\n"
     ]
    }
   ],
   "source": [
    "for label in labels:\n",
    "    print(f\"Leaves under order {new_element_index[emb_from_vocab[order]][:-5]}:\")\n",
    "    leaves_nodes = items[label]\n",
    "    print(len(leaves_nodes))\n",
    "    # for leaf in leaves_nodes:\n",
    "        # print(new_element_index[emb_from_vocab[leaf]][:-5])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e6ea1dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create item-label dataset\n",
    "def create_dataset_from_dict(orders_dict):\n",
    "    data = []\n",
    "    for order, leaf_nodes in orders_dict.items():\n",
    "        for node in leaf_nodes:\n",
    "            data.append({'item': node, 'label': order})\n",
    "    \n",
    "    df = pd.DataFrame(data)\n",
    "    return df\n",
    "\n",
    "dataset_df = create_dataset_from_dict(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "69197641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1035</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>538</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>514</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>645</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>518</td>\n",
       "      <td>494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>802</th>\n",
       "      <td>665</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>803</th>\n",
       "      <td>1170</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>804</th>\n",
       "      <td>155</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>480</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806</th>\n",
       "      <td>595</td>\n",
       "      <td>1137</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>807 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     item  label\n",
       "0    1035    494\n",
       "1     538    494\n",
       "2     514    494\n",
       "3     645    494\n",
       "4     518    494\n",
       "..    ...    ...\n",
       "802   665   1137\n",
       "803  1170   1137\n",
       "804   155   1137\n",
       "805   480   1137\n",
       "806   595   1137\n",
       "\n",
       "[807 rows x 2 columns]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5af87d7",
   "metadata": {},
   "source": [
    "### Distance-based label prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "596678de",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = list(set(dataset_df['label']))\n",
    "\n",
    "# Convert item and label names to embedding indices\n",
    "item_indices = [emb_from_vocab[item] for item in dataset_df['item']]\n",
    "label_indices = [emb_from_vocab[label] for label in unique_labels]\n",
    "\n",
    "# # Extract embeddings\n",
    "item_emb = hyp_cone.emb(torch.tensor(item_indices))\n",
    "label_embs = hyp_cone.emb(torch.tensor(label_indices))\n",
    "\n",
    "# Expand item and label embeddings to batch compute pairwise distances\n",
    "expanded_item_emb = item_emb.unsqueeze(1).expand(-1, len(unique_labels), -1)  # Shape: [num_items, num_labels, emb_dim]\n",
    "expanded_label_embs = label_embs.unsqueeze(0).expand(len(dataset_df), -1, -1)  # Shape: [num_items, num_labels, emb_dim]\n",
    "\n",
    "# Calculate pairwise hyperbolic distances\n",
    "# distances = expanded_item_emb.Hdist(expanded_label_embs)\n",
    "\n",
    "# Calculate pairwise Euclidean distances in the first (n-1) dimensions of the half-space\n",
    "differences = expanded_item_emb - expanded_label_embs\n",
    "# differences = differences[...,:-1]\n",
    "squared_differences = differences ** 2\n",
    "summed_squares = torch.sum(squared_differences, dim=2)\n",
    "distances = torch.sqrt(summed_squares)\n",
    "\n",
    "# Calculate softmax based on distances\n",
    "probabilities = torch.softmax(-distances, dim=1) \n",
    "\n",
    "# Get the predicted label (the one with the highest probability)\n",
    "predicted_label_idx = torch.argmax(probabilities, dim=1)\n",
    "predicted_labels = [unique_labels[idx] for idx in predicted_label_idx]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4add1b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.1512\n"
     ]
    }
   ],
   "source": [
    "# Calculate prediction accuracy\n",
    "def calculate_accuracy(predictions, true_labels):\n",
    "    correct_predictions = sum(p == t for p, t in zip(predictions, true_labels))\n",
    "    accuracy = correct_predictions / len(predictions)\n",
    "    return accuracy\n",
    "\n",
    "# Extract true labels from the dataset\n",
    "true_labels = dataset_df['label'].tolist()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = calculate_accuracy(predicted_labels, true_labels)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63507966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e163bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
